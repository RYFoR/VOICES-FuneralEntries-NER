# Documentation for VOICES-FuneralEntries-NER

This directory contains supporting documentation and guides for the VOICES-FuneralEntries-NER dataset and assesment experiments. The resources herein are intended to facilitate transparent reuse, reproducibility, and critical engagement with the data, methods, and annotation protocols developed as part of the VOICES project.

---

## Contents

- **Funeral Entry Image Collection**  
  A curated set of 12 original Funeral Entry images, each corresponding to a unique entry. These images, sourced from the annotated corpus in Transkribus, include the associated crest and title for each entry. This collection provides essential visual context for the manuscript material and supports both manual and automated transcription efforts.

- **Transkribus Annotation Guide**  
  The official annotation guide for the initial Funeral Entries. This document details the conventions, tag sets, and workflow used in Transkribus for segmenting, transcribing, and annotating the manuscript images. It is intended for researchers seeking to understand or replicate the annotation process.

- **Subset Descriptions**  
  Detailed descriptions of the dataset’s principal subsets:
  - **Transkribus**: Entries transcribed and annotated using the Transkribus platform, following the project’s established guidelines.
  - **EyeCR**: Entries processed with EyeCR, including a summary of the tool’s configuration and output characteristics.
  - **Manual**: Entries transcribed manually. This section outlines the constraints and editorial principles applied, such as normalization practices, treatment of abbreviations, and handling of uncertain readings. The description draws on the project’s internal drafts and expands upon them to provide comprehensive documentation.

- **Annotation Guide for Results**  
  A guide to the annotation schema and evaluation criteria used for benchmarking Handwritten Text Recognition (HTR) and Named Entity Recognition (NER) outputs. This document, adapted from previous project drafts, specifies the entity types, tagging conventions, and quality control measures employed in the creation of gold-standard annotations.

---

## Purpose

The documentation in this folder is designed to:
- Provide clear provenance and context for the dataset’s images and transcriptions.
- Enable other researchers to understand, reproduce, or extend the annotation and benchmarking workflows.
- Support critical assessment of the dataset’s structure, coverage, and methodological choices.


